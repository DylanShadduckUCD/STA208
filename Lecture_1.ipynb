{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Wine Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename:  /Users/Dylan/Desktop/School Stuff/Master's year/Spring 2021/STA 208/DavisSML/data/winequality-red.csv\n"
     ]
    }
   ],
   "source": [
    "folder = \"/Users/Dylan/Desktop/School Stuff/Master's year/Spring 2021/STA 208/DavisSML/data/\"\n",
    "filename = folder + \"winequality-red.csv\"\n",
    "print(\"Filename: \", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename, \"r\") as winefile:\n",
    "    head = winefile.readline()\n",
    "    winelist = [line.strip().split(\";\") for line in winefile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_array = np.array(winelist, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = wine_array[:, -1]\n",
    "x = wine_array[:,:-1]\n",
    "n,p = x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to define an intercept for the ordinary least squares model (OLS)\n",
    "X = np.hstack((np.ones((n,1)), x))\n",
    "wine_ols = sm.OLS(y, X)\n",
    "wine_res = wine_ols.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Fit of our Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.361</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.356</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   81.35</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 29 Mar 2021</td> <th>  Prob (F-statistic):</th> <td>1.79e-145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:39:39</td>     <th>  Log-Likelihood:    </th> <td> -1569.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1599</td>      <th>  AIC:               </th> <td>   3162.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1587</td>      <th>  BIC:               </th> <td>   3227.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   21.9645</td> <td>   21.195</td> <td>    1.036</td> <td> 0.300</td> <td>  -19.608</td> <td>   63.537</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.0250</td> <td>    0.026</td> <td>    0.963</td> <td> 0.336</td> <td>   -0.026</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -1.0836</td> <td>    0.121</td> <td>   -8.948</td> <td> 0.000</td> <td>   -1.321</td> <td>   -0.846</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.1826</td> <td>    0.147</td> <td>   -1.240</td> <td> 0.215</td> <td>   -0.471</td> <td>    0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0163</td> <td>    0.015</td> <td>    1.089</td> <td> 0.277</td> <td>   -0.013</td> <td>    0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -1.8742</td> <td>    0.419</td> <td>   -4.470</td> <td> 0.000</td> <td>   -2.697</td> <td>   -1.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.0044</td> <td>    0.002</td> <td>    2.009</td> <td> 0.045</td> <td>    0.000</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -0.0033</td> <td>    0.001</td> <td>   -4.480</td> <td> 0.000</td> <td>   -0.005</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>  -17.8805</td> <td>   21.633</td> <td>   -0.827</td> <td> 0.409</td> <td>  -60.313</td> <td>   24.552</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.4137</td> <td>    0.192</td> <td>   -2.159</td> <td> 0.031</td> <td>   -0.789</td> <td>   -0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>    0.9163</td> <td>    0.114</td> <td>    8.014</td> <td> 0.000</td> <td>    0.692</td> <td>    1.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.2762</td> <td>    0.026</td> <td>   10.429</td> <td> 0.000</td> <td>    0.224</td> <td>    0.328</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>27.376</td> <th>  Durbin-Watson:     </th> <td>   1.757</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  40.965</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.168</td> <th>  Prob(JB):          </th> <td>1.27e-09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.708</td> <th>  Cond. No.          </th> <td>1.13e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.13e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.361\n",
       "Model:                            OLS   Adj. R-squared:                  0.356\n",
       "Method:                 Least Squares   F-statistic:                     81.35\n",
       "Date:                Mon, 29 Mar 2021   Prob (F-statistic):          1.79e-145\n",
       "Time:                        11:39:39   Log-Likelihood:                -1569.1\n",
       "No. Observations:                1599   AIC:                             3162.\n",
       "Df Residuals:                    1587   BIC:                             3227.\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         21.9645     21.195      1.036      0.300     -19.608      63.537\n",
       "x1             0.0250      0.026      0.963      0.336      -0.026       0.076\n",
       "x2            -1.0836      0.121     -8.948      0.000      -1.321      -0.846\n",
       "x3            -0.1826      0.147     -1.240      0.215      -0.471       0.106\n",
       "x4             0.0163      0.015      1.089      0.277      -0.013       0.046\n",
       "x5            -1.8742      0.419     -4.470      0.000      -2.697      -1.052\n",
       "x6             0.0044      0.002      2.009      0.045       0.000       0.009\n",
       "x7            -0.0033      0.001     -4.480      0.000      -0.005      -0.002\n",
       "x8           -17.8805     21.633     -0.827      0.409     -60.313      24.552\n",
       "x9            -0.4137      0.192     -2.159      0.031      -0.789      -0.038\n",
       "x10            0.9163      0.114      8.014      0.000       0.692       1.141\n",
       "x11            0.2762      0.026     10.429      0.000       0.224       0.328\n",
       "==============================================================================\n",
       "Omnibus:                       27.376   Durbin-Watson:                   1.757\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               40.965\n",
       "Skew:                          -0.168   Prob(JB):                     1.27e-09\n",
       "Kurtosis:                       3.708   Cond. No.                     1.13e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.13e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a linear regression model on our train datasets\n",
    "n_train, p_train = X_train.shape\n",
    "X_train = np.hstack((np.ones((n_train,1)), X_train))\n",
    "wine_ols_train = sm.OLS(y_train, X_train)\n",
    "wine_res_train = wine_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
